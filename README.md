# Analyze Logs Script

A command-line Python tool for aggregating, summarizing, and visualizing load-test results stored as JSON files.

## Script: `analyze_logs.py`

This script performs the following steps:

1. **Load JSON Logs**
   - Reads all `*.json` files from a specified directory (`log_dir`).
   - Prints the list of files found and the total records loaded.
2. **Assemble DataFrame**
   - Flattens JSON into a Pandas DataFrame with columns:
     - `website` (URL under test)
     - `network_condition` (latency/download/upload tuple)
     - `tester` (`ClassicLoadTester` or `CacheV2LoadTester`)
     - `time_seconds` (cache-age in seconds)
     - `load_time_ms` (median load time in milliseconds)
3. **Summarize**
   - **Average load times** by `(network_condition, tester, time_seconds)`.
   - **Per-website enhancement** of CacheV2 over Classic:
     \[
       \text{enhancement} = \frac{T_{Classic} - T_{CacheV2}}{T_{Classic}}
     \]
   - Prints both tables to the console.
4. **Export CSVs**
   - `avg_load_times.csv` — contains the average load-time summary.
   - `per_site_enhancement.csv` — contains the per-website enhancement values.
   - Both files are saved into the `log_dir`.
5. **Plot Enhancement**
   - Using Matplotlib’s `Agg` backend (no GUI pop-ups), plots enhancement vs. cache-age for each website & network condition.
   - Saves the figure as `enhancement_curve.png` in `log_dir`.

## Prerequisites

- **Python 3.7+**
- **Pandas** and **Matplotlib**

Install dependencies:

```bash
pip install pandas matplotlib
```

## Usage

```bash
chmod +x analyze_logs.py
./analyze_logs.py <log_dir> [--no-plot]
```

- `<log_dir>`: Path to the directory containing your JSON log files.
- `--no-plot`: Skip drawing the enhancement plot (still exports CSVs).

### Example

```bash
./analyze_logs.py log/
# Output:
#   log/avg_load_times.csv
#   log/per_site_enhancement.csv
#   log/enhancement_curve.png
```

## File Descriptions

- **`analyze_logs.py`**: Main script. See comments in code for detailed function behavior.
- **`log/*.json`**: Input JSON files generated by your load-testing framework.

## Output Formats

### `avg_load_times.csv`

| network_condition               | tester            | time_seconds | avg_load_time_ms |
|---------------------------------|-------------------|--------------|------------------|
| `(latency:100, download:1MB/s…)` | ClassicLoadTester | 60           | 10492.77         |
| `(latency:100, download:1MB/s…)` | CacheV2LoadTester | 5649.46      |                  |

### `per_site_enhancement.csv`

| network_condition               | website             | time_seconds | enhancement |
|---------------------------------|---------------------|--------------|-------------|
| `(latency:100, download:1MB/s…)` | https://example.com | 60           | 0.461       |

- **enhancement** > 0 ⇒ CacheV2 is faster; < 0 ⇒ CacheV2 is slower.


## Quick Plot Script (`quick_plot.py`)

A lightweight script for generating per-network-condition performance plots directly from your JSON logs.

### Script Overview

This script:

1. **Reads** all JSON files in a `log/` directory into a nested data structure of the form:
   ```python
   data[network_condition][tester][time_seconds] = load_time_ms
   ```
2. **Plots** for each `network_condition` a line chart of:
   - **X‑axis**: cache-age (`time_seconds`, log scale)
   - **Y‑axis**: median page-load time (`load_time_ms`)
   - One series per tester (`ClassicLoadTester`, `CacheV2LoadTester`)
3. **Saves** each figure as `plot_<sanitized_network_condition>.png` in the current directory.

### Prerequisites

- Python 3.7+
- Matplotlib

Install:
```bash
pip install matplotlib
```

### Usage

1. Adjust the `log_dir` variable at the top of `quick_plot.py` if needed.
2. Run the script:
   ```bash
   python quick_plot.py
   ```
3. Find the generated `plot_*.png` files in your working directory.


-
